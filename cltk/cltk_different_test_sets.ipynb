{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a577b5",
   "metadata": {},
   "source": [
    "# CLTK on treebanks\n",
    "### This script running in a venv on Python 3.9.7, was used to apply POS tagging with the CLTK tagger on the treebank test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554a4595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2014cd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 12:15:38.310007: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from cltk import NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73cb58",
   "metadata": {},
   "source": [
    "This snippet is from [here](https://github.com/cltk/cltk/blob/master/notebooks/CLTK%20Demonstration.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0e51aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.1.6'.\n",
      "Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinStanzaProcess`, `LatinEmbeddingsProcess`, `StopsProcess`, `LatinLexiconProcess`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cltk.lexicon.processes.LatinLexiconProcess"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the default Pipeline for Latin\n",
    "cltk_nlp = NLP(language=\"lat\")\n",
    "# Removing ``LatinLexiconProcess`` for this demo b/c it is slow (adds ~9 mins total)\n",
    "cltk_nlp.pipeline.processes.pop(-1)\n",
    "# print(cltk_nlp.pipeline.processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9c7d9",
   "metadata": {},
   "source": [
    "### ITTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e1c0562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognized UD `feature_name` ('ConjType') with `feature_value` ('Expl').\n",
      "Please raise an issue at <https://github.com/cltk/cltk/issues> and include a small sample to reproduce the error.\n"
     ]
    }
   ],
   "source": [
    "# open the ittb file that contains only the tokens of the test set\n",
    "with open(\"../random-training-data-other-taggers/test_tok_ittb.txt\") as ittb:\n",
    "    # read and strip the lines\n",
    "    content = ittb.read().strip()\n",
    "# and analyze the content with cltk\n",
    "cltk_doc = cltk_nlp.analyze(text=content)\n",
    "\n",
    "# get all the tokens in a list\n",
    "toks = cltk_doc.tokens\n",
    "# get all the pos tags in a list\n",
    "pos_tags = cltk_doc.pos\n",
    "\n",
    "# write output token, pos into files\n",
    "with open(\"../random-training-data-other-taggers/test_sets/cltk_ittb.txt\", \"w\") as out:\n",
    "    for ind,token in enumerate(toks):\n",
    "        # add newline character at end of every line for formatting\n",
    "        row = token+\"\\t\"+pos_tags[ind]+\"\\n\"\n",
    "        out.write(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b2a12",
   "metadata": {},
   "source": [
    "### LLCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179a6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../random-training-data-other-taggers/test_tok_llct.txt\") as llct:\n",
    "    content2 = llct.read().strip()\n",
    "cltk_doc2 = cltk_nlp.analyze(text=content2)\n",
    "\n",
    "toks2 = cltk_doc2.tokens\n",
    "pos_tags2 = cltk_doc2.pos\n",
    "\n",
    "# write output token, pos into files\n",
    "with open(\"../random-training-data-other-taggers/test_sets/cltk_llct.txt\", \"w\") as out2:\n",
    "    for ind,token in enumerate(toks2):\n",
    "        row = token+\"\\t\"+pos_tags2[ind]+\"\\n\"\n",
    "        out2.write(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c3d51",
   "metadata": {},
   "source": [
    "### UDante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f11e1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../random-training-data-other-taggers/test_tok_udante.txt\") as udante:\n",
    "    content3 = udante.read().strip()\n",
    "cltk_doc3 = cltk_nlp.analyze(text=content3)\n",
    "\n",
    "toks3 = cltk_doc3.tokens\n",
    "pos_tags3 = cltk_doc3.pos\n",
    "\n",
    "# write output token, pos into files\n",
    "with open(\"../random-training-data-other-taggers/test_sets/cltk_udante.txt\", \"w\") as out3:\n",
    "    for ind,token in enumerate(toks3):\n",
    "        row = token+\"\\t\"+pos_tags3[ind]+\"\\n\"\n",
    "        out3.write(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80efb32f",
   "metadata": {},
   "source": [
    "### Perseus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8430003",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../random-training-data-other-taggers/test_tok_perseus.txt\") as perseus:\n",
    "    content5 = perseus.read().strip()\n",
    "cltk_doc5 = cltk_nlp.analyze(text=content5)\n",
    "\n",
    "toks5 = cltk_doc5.tokens\n",
    "pos_tags5 = cltk_doc5.pos\n",
    "        \n",
    "# write output token, pos into files\n",
    "with open(\"../random-training-data-other-taggers/test_sets/cltk_perseus.txt\", \"w\") as out5:\n",
    "    for ind,token in enumerate(toks5):\n",
    "        row = token+\"\\t\"+pos_tags5[ind]+\"\\n\"\n",
    "        out5.write(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac65ba49",
   "metadata": {},
   "source": [
    "Because cltk has problems with tagging the PROIEL data in one go, I used a different approach to try to navigate around that the kernel does not die during tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "133fa927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "with open(\"../random-training-data-other-taggers/test_tok_proiel.txt\") as proiel:\n",
    "    content4 = proiel.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa30338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i go through the list token by token and analyze it\n",
    "analyzed = []\n",
    "for tok in content4:\n",
    "    analyzed.append(cltk_nlp.analyze(text=tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3cedf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all tokens in a list and all pos tags in a list\n",
    "toks4 = [el.tokens for el in analyzed]\n",
    "pos_tags4 = [el.pos for el in analyzed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78f66b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output token, pos into files\n",
    "with open(\"../random-training-data-other-taggers/test_sets/cltk_proiel.txt\", \"w\") as out4:\n",
    "    for ind,token in enumerate(toks4):\n",
    "        row = token[0]+\"\\t\"+pos_tags4[ind][0]+\"\\n\"\n",
    "        out4.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09815c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (myvenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
