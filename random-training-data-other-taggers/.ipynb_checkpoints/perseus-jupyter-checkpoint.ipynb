{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26fe1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts from here: https://github.com/PerseusDL/treebank_data/tree/master/v2.1/Latin/texts\n",
    "# perseus: https://github.com/PerseusDL/treebank_data/tree/master/v2.1/Latin\n",
    "# https://github.com/PerseusDL/treebank_data/blob/master/v2.1/Latin/texts/phi0631.phi001.perseus-lat1.tb.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c2fc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import xml.etree.ElementTree as et "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f151a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â i need to combine all dfs and get samle from them\n",
    "filenames = [\"tlg0031.tlg027.perseus-lat1.tb.xml\",\"phi1351.phi005.perseus-lat1.tb.xml\",\n",
    "             \"phi1348.abo012.perseus-lat1.tb.xml\",\"phi1221.phi007.perseus-lat1.tb.xml\",\n",
    "             \"phi0975.phi001.perseus-lat1.tb.xml\",\"phi0972.phi001.perseus-lat1.xml\",\n",
    "             \"phi0959.phi006.perseus-lat1.tb.xml\",\"phi0690.phi003.perseus-lat1.tb.xml\",\n",
    "             \"phi0631.phi001.perseus-lat1.tb.xml\",\"phi0620.phi001.perseus-lat1.tb.xml\",\n",
    "             \"phi0474.phi013.perseus-lat1.tb.xml\",\"phi0448.phi001.perseus-lat1.tb.xml\"]\n",
    "\n",
    "# we have 12 files --> 300 sentences/12 files = 25 sents/file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d4c931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411, 562, 296, 60, 227, 532, 549, 368, 283, 176, 108, 268, 219, 26, 266, 278]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[49, 42, 79, 74, 160, 187, 95, 22, 155, 86, 171, 99, 129, 63, 45, 183, 121, 71, 189, 140, 76, 1, 193, 146, 194]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[260, 99, 211, 216, 306, 147, 220, 231, 82, 119, 156, 132, 22, 41, 23, 236, 320, 143, 265, 273, 331, 241, 175, 74, 344]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[25, 8, 52, 115, 81, 80, 56, 35, 23, 45, 55, 95, 75, 41, 111, 71, 112, 102, 12, 7, 90, 29, 108, 74, 78]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[243, 125, 339, 181, 297, 470, 26, 43, 365, 84, 292, 334, 18, 330, 295, 329, 156, 420, 79, 300, 196, 454, 299, 139, 256]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[781, 325, 678, 19, 744, 91, 931, 347, 747, 742, 594, 198, 899, 424, 868, 425, 232, 121, 127, 113, 345, 306, 83, 1118, 1004]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[298, 127, 164, 18, 62, 270, 149, 209, 102, 244, 103, 123, 224, 210, 251, 112, 215, 227, 219, 110, 255, 96, 16, 130, 129]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[62, 134, 53, 59, 106, 66, 36, 83, 13, 80, 144, 29, 145, 103, 10, 126, 99, 23, 110, 174, 146, 42, 86, 75, 120]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[657, 322, 430, 540, 220, 670, 274, 346, 401, 508, 76, 286, 642, 684, 195, 45, 404, 634, 130, 275, 683, 61, 171, 650, 475]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[291, 241, 206, 199, 111, 1, 108, 80, 6, 312, 131, 59, 202, 195, 113, 281, 27, 103, 82, 343, 311, 169, 287, 269, 225]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[13, 40, 17, 304, 57, 250, 287, 131, 311, 71, 21, 185, 267, 5, 152, 177, 38, 43, 278, 232, 195, 105, 159, 198, 119]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n",
      "[62, 51, 12, 9, 14, 46, 55, 53, 54, 45, 49, 28, 4, 40, 56, 68, 57, 19, 30, 27, 7, 35, 10, 23, 48]\n",
      "[('et', 'c--------'), ('cum', 'c--------'), ('locuta', 'v-prppnn-'), ('fuissent', 'v3plsa---'), ('septem', 'm--------'), ('tonitrua', 'n-p---nn-'), ('scripturus', 'v-sfpamn-'), ('eram', 'v1siia---'), (';', 'u--------'), ('et', 'c--------')]\n"
     ]
    }
   ],
   "source": [
    "# list for all the random sentences and tags from all files\n",
    "random_sents = []\n",
    "random.seed(4)\n",
    "def extract_samples(filename):\n",
    "    # all sents and tags from this file\n",
    "    total_sents = []\n",
    "    total_tags = []\n",
    "\n",
    "    # parse the file and get root and body\n",
    "    tree = et.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    body = root.find(\"body\")\n",
    "    #print(body)\n",
    "    for node in body: \n",
    "        # lists to store the words and their tags\n",
    "        wordlist = []\n",
    "        taglist = []\n",
    "        # find the words\n",
    "        words = node.findall(\"word\")\n",
    "        # get the needed attributes\n",
    "        for word in words:\n",
    "            wordlist.append(word.attrib.get(\"form\"))\n",
    "            taglist.append(word.attrib.get(\"postag\"))\n",
    "        # append the lists to the lists that contain the sentences/tags from the whole file\n",
    "        total_sents.append(wordlist)\n",
    "        total_tags.append(taglist)\n",
    "\n",
    "    # Generate 25 unique random indices\n",
    "    random_indices = random.sample(range(len(total_sents)), 25)\n",
    "\n",
    "    print(random_indices)\n",
    "\n",
    "    # Extract corresponding elements from both lists\n",
    "    random_elements_sents = [total_sents[i] for i in random_indices]\n",
    "    random_elements_tags = [total_tags[i] for i in random_indices]\n",
    "\n",
    "    # safe as tuples\n",
    "    for i,e in enumerate(random_elements_sents):\n",
    "        for idx,word in enumerate(e):\n",
    "            random_sents.append((word,random_elements_tags[i][idx]))\n",
    "\n",
    "\n",
    "    print(random_sents[:10])\n",
    "\n",
    "for file in filenames:\n",
    "    extract_samples(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "549ee588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>et</td>\n",
       "      <td>c--------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cum</td>\n",
       "      <td>c--------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>locuta</td>\n",
       "      <td>v-prppnn-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuissent</td>\n",
       "      <td>v3plsa---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>septem</td>\n",
       "      <td>m--------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>locum</td>\n",
       "      <td>n-s---ma-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>nostri</td>\n",
       "      <td>p-p---mn-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>castris</td>\n",
       "      <td>n-p---nd-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>delegerant</td>\n",
       "      <td>v3plia---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>.</td>\n",
       "      <td>u--------</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5551 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           token        pos\n",
       "0             et  c--------\n",
       "1            cum  c--------\n",
       "2         locuta  v-prppnn-\n",
       "3       fuissent  v3plsa---\n",
       "4         septem  m--------\n",
       "...          ...        ...\n",
       "5546       locum  n-s---ma-\n",
       "5547      nostri  p-p---mn-\n",
       "5548     castris  n-p---nd-\n",
       "5549  delegerant  v3plia---\n",
       "5550           .  u--------\n",
       "\n",
       "[5551 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(random_sents, columns = [\"token\",\"pos\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f865e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to map the pos tags to the upos tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034544ee",
   "metadata": {},
   "source": [
    "- n\tnoun\n",
    "- v\tverb\n",
    "- a\tadjective\n",
    "- d\tadverb\n",
    "- c\tconjunction\n",
    "- r\tadposition\n",
    "- p\tpronoun\n",
    "- m\tnumeral\n",
    "- i\tinterjection\n",
    "- e\texclamation\n",
    "- u\tpunctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "890a4039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        token        pos first_pos   upos\n",
      "0          et  c--------         c   CONJ\n",
      "1         cum  c--------         c   CONJ\n",
      "2      locuta  v-prppnn-         v   VERB\n",
      "3    fuissent  v3plsa---         v   VERB\n",
      "4      septem  m--------         m    NUM\n",
      "5    tonitrua  n-p---nn-         n   NOUN\n",
      "6  scripturus  v-sfpamn-         v   VERB\n",
      "7        eram  v1siia---         v   VERB\n",
      "8           ;  u--------         u  PUNCT\n",
      "9          et  c--------         c   CONJ\n"
     ]
    }
   ],
   "source": [
    "# first part: part of speech tag\n",
    "\n",
    "# no difference of SCONJ and CCONJ here\n",
    "mapped={\n",
    "    \"n\" : \"NOUN\",\n",
    "    \"v\" : \"VERB\",\n",
    "    \"a\" : \"ADJ\",\n",
    "    \"d\" : \"ADV\",\n",
    "    \"c\" : \"CONJ\",\n",
    "    \"r\" : \"ADP\",\n",
    "    \"p\" : \"PRON\",\n",
    "    \"m\" : \"NUM\",\n",
    "    \"i\" : \"INTJ\",\n",
    "    \"e\" : \"X\",\n",
    "    \"u\" : \"PUNCT\",\n",
    "    \"None\": \"None\",\n",
    "    \"-\" : \"None\"\n",
    "}\n",
    "\n",
    "def extract_first_letter(pos):\n",
    "    \"\"\"This function will return the first letter, that means in that case the pos tag\"\"\"\n",
    "    if pos != None and not(len(pos)==0):\n",
    "        return pos[0]\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "\n",
    "def map_postags(df):\n",
    "    df[\"first_pos\"] = df[\"pos\"].apply(extract_first_letter)\n",
    "    df[\"upos\"] = df[\"first_pos\"].map(mapped)\n",
    "    return df\n",
    "        \n",
    "def clean_none(df):\n",
    "    df = df[df['upos'] != 'None']\n",
    "    return df\n",
    "\n",
    "\n",
    "mapped_upos_df =  clean_none(map_postags(df))\n",
    "print(mapped_upos_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f56a9505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>first_pos</th>\n",
       "      <th>upos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>et</td>\n",
       "      <td>c--------</td>\n",
       "      <td>c</td>\n",
       "      <td>CONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cum</td>\n",
       "      <td>c--------</td>\n",
       "      <td>c</td>\n",
       "      <td>CONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>locuta</td>\n",
       "      <td>v-prppnn-</td>\n",
       "      <td>v</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuissent</td>\n",
       "      <td>v3plsa---</td>\n",
       "      <td>v</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>septem</td>\n",
       "      <td>m--------</td>\n",
       "      <td>m</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>locum</td>\n",
       "      <td>n-s---ma-</td>\n",
       "      <td>n</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>nostri</td>\n",
       "      <td>p-p---mn-</td>\n",
       "      <td>p</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>castris</td>\n",
       "      <td>n-p---nd-</td>\n",
       "      <td>n</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>delegerant</td>\n",
       "      <td>v3plia---</td>\n",
       "      <td>v</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>.</td>\n",
       "      <td>u--------</td>\n",
       "      <td>u</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5517 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           token        pos first_pos   upos\n",
       "0             et  c--------         c   CONJ\n",
       "1            cum  c--------         c   CONJ\n",
       "2         locuta  v-prppnn-         v   VERB\n",
       "3       fuissent  v3plsa---         v   VERB\n",
       "4         septem  m--------         m    NUM\n",
       "...          ...        ...       ...    ...\n",
       "5546       locum  n-s---ma-         n   NOUN\n",
       "5547      nostri  p-p---mn-         p   PRON\n",
       "5548     castris  n-p---nd-         n   NOUN\n",
       "5549  delegerant  v3plia---         v   VERB\n",
       "5550           .  u--------         u  PUNCT\n",
       "\n",
       "[5517 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_upos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2048a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/perseus-random-300.txt\",\"w\") as outfile:\n",
    "    for index,row in mapped_upos_df.iterrows():\n",
    "        out = str(row[\"token\"])+\"\\t\"+row[\"upos\"]+\"\\n\"\n",
    "        outfile.write(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91394a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb3e9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
